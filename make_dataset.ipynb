{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34407a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (0.4.1)\n",
      "Requirement already satisfied: pandas in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (2.3.1)\n",
      "Requirement already satisfied: nltk in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (3.9.1)\n",
      "Requirement already satisfied: torch in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: transformers in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (4.54.1)\n",
      "Requirement already satisfied: kagglesdk<1.0,>=0.1.14 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from kagglehub) (0.1.15)\n",
      "Requirement already satisfied: packaging in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from kagglehub) (6.0.3)\n",
      "Requirement already satisfied: requests in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from kagglehub) (2.32.5)\n",
      "Requirement already satisfied: tqdm in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: protobuf in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from kagglesdk<1.0,>=0.1.14->kagglehub) (6.32.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: click in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from nltk) (8.2.2)\n",
      "Requirement already satisfied: joblib in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from nltk) (2025.7.34)\n",
      "Requirement already satisfied: filelock in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from requests->kagglehub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from requests->kagglehub) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/chengyi/anaconda3/envs/DataSci/lib/python3.13/site-packages (from requests->kagglehub) (2025.7.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub pandas nltk torch scikit-learn transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d0fa2c",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e51c72a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/chengyi/.cache/kagglehub/datasets/suchintikasarkar/sentiment-analysis-for-mental-health/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "# Download via Kaggle's API\n",
    "path = kagglehub.dataset_download(\"suchintikasarkar/sentiment-analysis-for-mental-health\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "532d2f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data length: 53043\n",
      "After dropping na values: 52681\n",
      "After dropping duplicates: 52681\n"
     ]
    }
   ],
   "source": [
    "# Drop NA values & duplicates\n",
    "df = pd.read_csv(path + \"/Combined Data.csv\")\n",
    "print(\"Raw data length:\", len(df))\n",
    "print(\"After dropping na values:\", len(df.dropna()))\n",
    "print(\"After dropping duplicates:\", len(df.dropna().drop_duplicates())) # No duplicates present\n",
    "df = df.dropna().drop_duplicates().drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0eb8fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping, confused mind, restless hear...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all wrong, back off dear, forward doubt. stay ...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i've shifted my focus to something else but i'...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i'm restless and restless, it's been a month n...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement   status\n",
       "0                                         oh my gosh  anxiety\n",
       "1  trouble sleeping, confused mind, restless hear...  anxiety\n",
       "2  all wrong, back off dear, forward doubt. stay ...  anxiety\n",
       "3  i've shifted my focus to something else but i'...  anxiety\n",
       "4  i'm restless and restless, it's been a month n...  anxiety"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle casing\n",
    "df[\"statement\"] = df[\"statement\"].str.lower()\n",
    "df[\"status\"] = df[\"status\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97288de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52681 entries, 0 to 53042\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   statement  52681 non-null  string  \n",
      " 1   status     52681 non-null  category\n",
      "dtypes: category(1), string(1)\n",
      "memory usage: 874.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Handle data types\n",
    "df[\"statement\"] = df[\"statement\"].astype(\"string\")\n",
    "df[\"status\"] = df[\"status\"].astype(\"category\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "876da79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       52681.0\n",
       "mean       578.6781\n",
       "std      846.248914\n",
       "min             2.0\n",
       "25%            80.0\n",
       "50%           317.0\n",
       "75%           752.0\n",
       "max         32759.0\n",
       "Name: statement, dtype: Float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trailing / beginning whitespaces\n",
    "df[\"statement\"] = df[\"statement\"].str.strip()\n",
    "df[\"status\"] = df[\"status\"].str.strip()\n",
    "df[\"statement\"].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9522d4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       52681.0\n",
       "mean     564.987548\n",
       "std      827.183457\n",
       "min             2.0\n",
       "25%            77.0\n",
       "50%           308.0\n",
       "75%           735.0\n",
       "max         31499.0\n",
       "Name: statement, dtype: Float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Non-alphanumeric characters only\n",
    "df[\"statement\"] = df[\"statement\"].str.replace(r\"[^a-zA-Z0-9\\s]\", \"\", regex=True)\n",
    "df[\"statement\"].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1943e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       52681.0\n",
       "mean     564.154705\n",
       "std      826.122235\n",
       "min             1.0\n",
       "25%            77.0\n",
       "50%           308.0\n",
       "75%           734.0\n",
       "max         31499.0\n",
       "Name: statement, dtype: Float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize spacing\n",
    "df[\"statement\"] = df[\"statement\"].str.replace(r\"\\s+\", \" \", regex=True)\n",
    "df[\"statement\"].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89222378",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e76079e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52681 entries, 0 to 52680\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   statement  52681 non-null  object\n",
      " 1   status     52681 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 823.3+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oh my gosh</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trouble sleeping confused mind restless heart ...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all wrong back off dear forward doubt stay in ...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ive shifted my focus to something else but im ...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im restless and restless its been a month now ...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement   status\n",
       "0                                         oh my gosh  anxiety\n",
       "1  trouble sleeping confused mind restless heart ...  anxiety\n",
       "2  all wrong back off dear forward doubt stay in ...  anxiety\n",
       "3  ive shifted my focus to something else but im ...  anxiety\n",
       "4  im restless and restless its been a month now ...  anxiety"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf2e388",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea268db",
   "metadata": {},
   "source": [
    "This was done by Ariel and imported into Google Drive, let's load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06599f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# CHANGE ME\n",
    "train_path = 'raw_train.csv'\n",
    "val_path = 'raw_val.csv'\n",
    "test_path = 'raw_test.csv'\n",
    "\n",
    "# Read into df\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6c3700",
   "metadata": {},
   "source": [
    "# Create features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b1069",
   "metadata": {},
   "source": [
    "I made some helper functions to make the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7cb9b135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CountVectorizer',\n",
       " 'DEFAULT_MODEL',\n",
       " 'DEFAULT_TOKENIZER',\n",
       " 'DEVICE',\n",
       " 'DistilBertModel',\n",
       " 'DistilBertTokenizer',\n",
       " 'SIA',\n",
       " 'SentimentIntensityAnalyzer',\n",
       " 'TfidfVectorizer',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'avg_sentence_length_in_characters',\n",
       " 'avg_sentence_length_in_words',\n",
       " 'avg_word_length',\n",
       " 'character_count',\n",
       " 'countvec',\n",
       " 'get_embeddings',\n",
       " 'nltk',\n",
       " 'reps_ratio',\n",
       " 'sia_sentiment',\n",
       " 'tfidfvec',\n",
       " 'torch',\n",
       " 'word_count',\n",
       " 'word_ratio']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import make_features_helper as helper\n",
    "\n",
    "dir(helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b1e1d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/chengyi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/chengyi/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'make_features_helper' from '/home/chengyi/Desktop/Classes/ECS171/ECS171-Final-Project/make_features_helper.py'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(helper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f61f80",
   "metadata": {},
   "source": [
    "For the vectorization features, we only want to fit on the training data, but still transform on the other splits for easy access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1348244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vectorizers\n",
    "train_tfidf, tfidfvec = helper.tfidfvec(train_df['statement'])\n",
    "train_count, countvec = helper.countvec(train_df['statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Put into dataframe.\n",
    "# For later use: np.vstack(df['tfidf_vec'])\n",
    "train_df['tfidf_vec'] = list(train_tfidf.toarray())\n",
    "train_df['count_vec'] = list(train_count.toarray())\n",
    "val_df['tfidf_vec'] = list(tfidfvec.transform(val_df['statement']).toarray())\n",
    "val_df['count_vec'] = list(countvec.transform(val_df['statement']).toarray())\n",
    "test_df['tfidf_vec'] = list(tfidfvec.transform(test_df['statement']).toarray())\n",
    "test_df['count_vec'] = list(countvec.transform(test_df['statement']).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d7eb79",
   "metadata": {},
   "source": [
    "For pretrained embedding features, we can iterate through the whole dataset no problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eca74cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4453e-02, -2.7182e-01, -1.4040e-01, -6.6006e-02,  4.6744e-02,\n",
       "         -3.6045e-01,  1.9694e-01,  5.6017e-01,  1.7628e-01, -3.7279e-01,\n",
       "         -4.5718e-02, -1.4598e-01, -2.5549e-01,  2.5197e-01,  2.3573e-02,\n",
       "          3.6898e-02, -4.4133e-02,  2.6953e-01, -6.9140e-03,  1.4042e-01,\n",
       "         -6.6925e-02, -1.7396e-01, -2.6942e-01,  5.3961e-02,  2.6116e-02,\n",
       "         -2.0509e-02,  2.1273e-02, -1.2333e-01,  4.3591e-02, -2.3034e-01,\n",
       "          7.1838e-02,  1.8205e-01, -3.1158e-01, -2.8259e-01, -7.8816e-02,\n",
       "          2.0568e-01,  5.6633e-02, -1.0214e-01, -1.4757e-01, -3.1617e-02,\n",
       "         -5.3188e-01,  7.5297e-02,  1.4844e-01,  8.5746e-03,  3.0512e-01,\n",
       "         -1.6850e-01, -2.6342e+00, -1.2698e-01, -2.5662e-01, -4.0931e-01,\n",
       "          1.6262e-02,  1.2963e-01,  3.2765e-01,  4.0754e-01,  6.3290e-01,\n",
       "          3.3945e-01, -2.4992e-01,  2.2208e-01, -7.5843e-03,  4.0662e-01,\n",
       "          1.1378e-01,  6.3623e-02, -2.5635e-01, -1.5354e-01, -1.0807e-02,\n",
       "          4.6236e-02,  2.0253e-02,  6.6411e-01, -5.3850e-01,  3.4024e-01,\n",
       "         -2.0799e-01, -2.1558e-01,  3.4040e-01, -2.9750e-01,  2.0448e-01,\n",
       "          2.5498e-01, -2.1954e-01,  1.2546e-01, -3.0110e-01,  2.0305e-01,\n",
       "         -1.9956e-01,  5.2198e-01,  3.1976e-01, -1.0564e-01, -1.0332e-01,\n",
       "          1.7685e-01, -6.0480e-01, -3.7145e-01,  4.0574e-01,  3.7700e-01,\n",
       "         -2.4209e-01, -3.0994e-01,  2.1362e-01,  2.8037e-01,  6.6073e-01,\n",
       "         -3.2597e-01, -2.2490e-01, -3.4984e-02,  1.6648e-01,  2.0925e-01,\n",
       "          1.7993e-01, -2.7034e-01, -3.4561e-02, -5.8818e-01,  2.2053e-01,\n",
       "          6.1131e-03, -3.8059e-01, -4.2715e-01,  1.6620e-01, -2.4240e+00,\n",
       "          3.0948e-01,  1.1741e-01, -2.5902e-01, -4.4560e-01, -9.8856e-02,\n",
       "          2.2543e-01,  3.3802e-01, -8.6093e-02,  6.6802e-02, -1.0654e-01,\n",
       "          1.6296e-01,  2.8429e-01,  4.9473e-02, -2.1518e-01, -8.2731e-02,\n",
       "          1.5990e-01,  1.7021e-01, -1.8341e-01,  2.5635e-01, -6.7669e-02,\n",
       "          3.1586e-01,  6.2278e-01,  2.2440e-01, -2.8240e-02, -3.7554e-01,\n",
       "          3.8511e-01,  2.5353e-01, -2.8855e-03, -5.9561e-02, -5.4854e-02,\n",
       "         -2.0078e-01, -7.3424e-03, -2.7643e+00,  3.2510e-01,  8.3815e-01,\n",
       "          1.9047e-01,  1.7741e-01, -7.8799e-02,  1.5791e-01,  2.5765e-01,\n",
       "          2.6476e-01,  1.7253e-01, -9.1151e-02,  9.2302e-02, -3.7159e-01,\n",
       "          1.9081e-01, -2.6729e-01, -2.6233e-01,  2.3624e-01,  1.2933e-01,\n",
       "          3.3779e-01, -1.5407e-01, -2.4542e-01, -9.2232e-02, -1.0773e-01,\n",
       "          2.4299e-01,  1.7760e-01,  1.9473e-01,  2.3728e-01,  1.3365e-05,\n",
       "         -1.4001e-01,  1.0033e-01,  4.9401e-01, -2.0414e-01,  2.3227e-01,\n",
       "          1.0099e-01,  1.7680e-01,  5.6028e-01, -2.3550e-02, -3.0329e-01,\n",
       "         -3.8598e-01,  5.1415e-01,  1.7247e-01, -1.0024e-01, -1.3206e-01,\n",
       "          1.6049e-02,  5.1248e-01, -2.2101e-01, -2.3967e-01,  2.8758e-01,\n",
       "         -1.7370e-01, -2.3411e-01, -6.3038e-03,  3.4117e-01,  4.4766e-01,\n",
       "         -2.8270e-01,  4.7577e-02, -2.8908e-01,  3.0510e-02,  4.5481e-01,\n",
       "         -8.5648e-02, -6.4954e-02, -1.6762e-02, -2.3227e-02, -4.5676e-02,\n",
       "          3.6639e+00,  9.1224e-03, -2.4510e-01,  3.4127e-02,  3.3620e-01,\n",
       "         -2.8517e-01, -2.1524e-01,  1.4326e-01, -2.2682e-02,  2.8529e-02,\n",
       "          2.3920e-01,  7.0136e-02, -2.3820e-02, -2.1270e-01, -1.4542e-01,\n",
       "          2.4795e-01,  8.6962e-02, -2.9005e-01,  3.4926e-01,  5.7473e-02,\n",
       "          4.5224e-01, -2.2349e-02,  4.6818e-01,  1.0122e-01, -1.4189e+00,\n",
       "          1.2474e-01, -1.5567e-02, -4.9378e-02,  4.9523e-01, -2.3093e-01,\n",
       "         -2.0857e-01, -2.5251e-01, -6.3841e-02, -6.8097e-02,  1.3759e-02,\n",
       "         -1.8924e-01,  1.1767e-01,  2.7861e-01,  3.3763e-01, -4.0146e-01,\n",
       "          7.4708e-01, -1.7009e-01,  1.1163e-01,  4.0428e-01, -2.3180e-01,\n",
       "          2.9726e-01, -5.9101e-02,  7.9246e-04, -4.0706e-01,  3.1458e-01,\n",
       "         -1.2052e-02,  7.8197e-02,  2.9451e-01, -4.4700e-01, -3.2440e-01,\n",
       "         -4.3119e-01,  3.3643e-02,  3.1913e-01,  7.3657e-02, -5.0194e-01,\n",
       "         -6.6139e-01,  1.1912e-01, -1.5057e-01,  8.9631e-02, -1.4376e-01,\n",
       "         -2.1432e-01, -2.9010e-01, -4.1961e-01, -3.4324e+00, -2.6948e-01,\n",
       "         -8.0809e-02,  4.3968e-01,  3.6767e-01, -6.0159e-02, -1.7727e-02,\n",
       "          1.8015e-01,  2.3553e-01, -6.3642e-01,  5.9271e-01,  3.3752e-01,\n",
       "         -4.9798e-02,  2.1813e-01, -3.3096e-01,  3.0024e-02,  1.8407e-03,\n",
       "         -3.3990e-01, -1.5131e-01, -2.5310e-01,  2.3505e-01,  3.6528e-01,\n",
       "         -2.4914e-01,  4.2566e-01,  2.2567e-02, -2.2632e-02, -1.8411e-01,\n",
       "         -2.5537e-01, -2.8660e-01,  1.3157e-01,  4.0811e-02, -4.3684e-01,\n",
       "          2.6962e-01, -3.8200e-01, -6.1551e-01, -2.1179e+00, -5.2990e-02,\n",
       "         -8.4844e-02, -3.3051e-01,  6.0552e-02, -2.0051e-01,  4.8657e-01,\n",
       "         -1.7062e-01, -3.0859e-01,  1.4694e-01,  3.8467e-02, -1.9852e-01,\n",
       "         -4.7472e-03,  9.6958e-02,  2.5719e-01,  3.5130e-01,  3.4701e-01,\n",
       "         -1.1493e-01,  8.0840e-02,  2.2739e-01, -1.8552e-01, -2.5695e-01,\n",
       "          8.7943e-02,  1.0771e-01,  3.4396e-02,  9.2564e-01, -3.4627e-01,\n",
       "         -6.5576e-02, -1.3124e-01, -1.5854e-01,  9.1784e-03, -3.0004e-01,\n",
       "         -1.2826e-02, -4.4199e-02, -1.4354e-01, -3.2145e-01,  3.0125e-02,\n",
       "          4.1060e-01,  4.1520e-01, -1.4721e-01,  5.6731e-02,  7.5537e-01,\n",
       "         -1.0055e-01, -4.4080e-02,  6.4793e-01,  2.3829e-01,  3.7382e-01,\n",
       "         -9.5597e-02, -9.7045e-02,  5.2353e-01,  1.3443e-01,  4.5916e-03,\n",
       "          1.3422e+00, -1.1499e-01,  1.5398e-01, -2.0689e-01,  1.7992e-01,\n",
       "          2.0252e-02,  5.4074e-02,  2.5722e-01,  5.3737e-01, -3.2695e-01,\n",
       "          3.1617e-01, -1.7279e-01,  1.9490e-01, -4.2063e-01, -5.0265e-02,\n",
       "         -5.0918e-01,  9.8551e-02,  7.0715e-02, -9.6731e-02,  5.3635e-01,\n",
       "          1.0205e-02, -9.3873e-01, -2.3429e-01,  2.0242e-01, -3.5205e-02,\n",
       "          1.7897e-01, -1.3750e-01,  1.6404e-01, -3.4630e-01, -2.0629e-01,\n",
       "         -4.0733e-01,  3.7781e-01, -2.1410e-01, -2.4241e-01, -1.5051e-01,\n",
       "         -1.0604e-01, -4.6422e-01, -3.3587e-01, -1.2342e-01,  1.2364e-01,\n",
       "          7.2585e-02,  2.9220e-01,  9.6161e-02,  1.3771e-01,  4.2363e-01,\n",
       "         -1.2509e+00,  2.0479e-01, -4.8966e-02,  4.5973e-02, -4.9473e-01,\n",
       "         -4.1658e-02,  3.6912e-02, -2.1043e-01, -4.4468e-02, -7.4503e-01,\n",
       "          1.2989e-01, -3.2756e-01,  2.5325e-01, -2.4141e-01, -6.3602e-02,\n",
       "         -1.5049e-01, -1.9356e-01,  7.1031e-01, -2.6661e-01,  3.2237e-02,\n",
       "          4.8305e-01,  1.8573e-01,  2.6176e-01,  1.0041e-01,  2.4963e-01,\n",
       "         -2.7075e-01, -1.1310e-01, -6.9855e-02, -3.1221e-01,  1.5161e-01,\n",
       "         -5.1944e-01, -1.9173e-01, -2.0775e-01,  6.7862e-02, -1.6587e-01,\n",
       "         -3.1220e-01, -3.7917e-01,  1.6740e-01, -5.1226e-01, -2.3390e-01,\n",
       "          2.7960e-02,  1.2431e-01,  2.4556e-01, -2.1009e-01,  2.6535e-01,\n",
       "         -4.2374e-01,  3.8483e-01, -8.5613e-02,  7.3389e-01, -1.0460e-01,\n",
       "         -2.0322e-01,  1.0317e-02,  4.1771e-01, -4.8274e-01, -2.0876e-01,\n",
       "         -2.0265e-01, -5.3674e-01,  2.8924e-01,  6.7826e-02,  8.7753e-02,\n",
       "         -9.0110e-02,  5.9538e-02, -2.0051e-02, -1.7912e-01,  1.1082e-01,\n",
       "         -1.5158e+00,  2.5722e-01,  1.0765e-01,  1.4573e-01,  1.3761e-01,\n",
       "         -3.0230e-01, -2.9196e-01,  2.7076e-01,  2.2473e-02,  5.1581e-02,\n",
       "         -1.4039e-02, -1.0707e-01,  2.0627e-02, -7.3955e-02,  1.6068e-01,\n",
       "          6.6264e-02,  1.6936e-01,  2.0838e-01, -2.2559e-01, -2.4112e-01,\n",
       "         -8.4064e-02,  4.0336e-01,  1.3088e-01, -3.2709e-02,  7.8714e-03,\n",
       "          5.6807e-02, -1.2212e-01,  1.5159e-01, -1.1656e-01,  1.4879e-01,\n",
       "         -2.3952e-01, -3.9581e-01, -5.5762e-01, -5.3012e-01,  8.5385e-02,\n",
       "          4.6125e-02,  3.6064e-01,  1.2305e-01,  5.2328e-01,  2.9657e-01,\n",
       "         -6.8589e-01,  5.6128e-01, -1.3620e-01, -4.8002e-02,  6.9546e-01,\n",
       "          1.7636e-02, -1.6567e-01,  2.8504e-01,  1.4175e-01, -2.1740e-01,\n",
       "         -1.3039e-01, -3.5782e-01,  1.3762e-01,  7.3842e-02,  9.2891e-02,\n",
       "         -3.7491e-02,  3.1649e-01,  1.1409e-01, -4.2107e-01, -6.3155e-02,\n",
       "          3.7692e-01, -1.3808e-01, -2.5590e-01,  3.3640e-01,  2.2060e-02,\n",
       "         -5.5783e-01, -2.6477e-01, -1.9832e-01, -3.6497e-02, -2.1873e-02,\n",
       "          3.5089e-01,  7.5959e-02,  7.5004e-02,  2.1984e-01, -3.6215e-01,\n",
       "          6.9093e-02, -1.3764e-02,  2.6062e-01,  2.3701e-02, -9.7867e-02,\n",
       "          5.5064e-02, -4.3028e-01, -4.5318e-01,  3.0851e-01, -3.6919e-01,\n",
       "          4.2638e-01, -1.4863e-01,  1.5273e-01,  1.5823e-01,  7.4408e-02,\n",
       "         -2.3631e-01, -2.3502e-01, -4.5105e-02, -4.3955e-02, -9.6458e-02,\n",
       "         -1.2594e-01,  2.0851e-01,  1.4007e-01,  1.3082e-01, -2.6931e-02,\n",
       "          2.3708e-02,  5.5250e-01,  4.2490e-01,  3.9845e-01,  2.9520e-01,\n",
       "          1.6789e-01,  3.7163e-01, -2.5962e-01, -1.7600e-01,  3.7839e-02,\n",
       "         -3.4206e-02, -1.3392e-01, -1.8103e-01,  1.2894e-01,  2.6827e-01,\n",
       "         -4.4733e-01, -1.2552e-01, -2.9549e-01,  1.8931e+00,  5.0702e-01,\n",
       "         -1.5256e-01,  2.0654e-01,  4.8060e-01, -3.0553e-01, -1.1328e-01,\n",
       "          2.3010e-01, -1.4379e-01,  3.8824e-01, -1.3902e-01,  4.6809e-01,\n",
       "         -5.4501e-02,  2.6700e-01,  6.2263e-01,  4.6593e-01,  5.9975e-02,\n",
       "         -2.2516e-01, -4.4630e-01, -1.1151e-02, -1.8657e-01,  6.0494e-01,\n",
       "          5.8361e-01,  1.2010e-01,  6.9293e-02,  2.7871e-01,  7.1597e-02,\n",
       "         -2.4575e-01,  1.4059e-01,  2.2459e-01, -3.2039e-01,  1.2616e-01,\n",
       "          3.5174e-01,  4.0853e-01, -4.6564e-01, -7.0558e-02,  6.6350e-03,\n",
       "         -3.3831e-01, -4.4628e-01, -1.2597e-01, -2.2901e-02, -4.3081e-01,\n",
       "          4.5081e-01,  1.6870e-01, -1.9543e-01,  3.7080e-01, -4.2334e-01,\n",
       "         -4.4013e-01,  2.9166e-01,  4.4255e-01, -1.0566e-01,  9.4071e-02,\n",
       "         -3.7246e-01,  2.1961e-01,  2.8765e-02, -2.5419e-01,  2.2647e-01,\n",
       "          1.1735e-01, -2.0552e-01,  2.1004e-01,  1.5057e-01,  3.2141e-01,\n",
       "          3.1810e-01, -4.6387e-02,  2.0216e-01,  4.8863e-01, -2.6130e-01,\n",
       "          1.1218e-01,  3.0885e-01, -1.4298e-01,  4.1194e-02,  4.0701e-01,\n",
       "          2.3443e-01,  3.8706e-01,  5.4374e-02,  1.2968e-01,  5.4047e-01,\n",
       "          1.1523e-01, -2.2140e-01, -2.5265e+00,  3.0414e-01, -1.2276e-01,\n",
       "          8.2604e-02, -1.8353e-01,  2.0375e-01,  3.0940e-01,  1.1248e-01,\n",
       "          3.1277e-01, -5.9784e-02,  2.6229e-01,  2.4190e-01,  6.0484e-01,\n",
       "          6.3101e-02,  8.8673e-02, -7.9021e-03,  1.5262e-01, -7.6505e-02,\n",
       "          4.0617e-02, -4.9012e-01,  2.9877e-02,  2.4922e-01, -7.5333e-02,\n",
       "         -3.0364e-01, -4.2859e-01,  7.5157e-02, -2.9719e-01, -3.5835e-01,\n",
       "         -2.1652e-03,  9.4019e-01, -3.6018e-01,  6.6436e-01, -3.5525e-01,\n",
       "         -5.7043e-02, -5.0940e-02, -1.1010e-01, -1.6335e-01,  1.9645e-01,\n",
       "          2.4810e-01,  1.7749e-01, -1.5876e-01,  3.0629e-01, -7.1884e-02,\n",
       "          2.5344e-01,  5.0483e-02,  6.0031e-02,  6.3542e-01, -1.9205e-01,\n",
       "          2.1453e-01, -4.9283e-01, -1.8477e-01,  1.1968e-01,  3.5171e-01,\n",
       "         -1.8167e-01, -2.1720e-01,  5.2272e-02,  2.6782e-01,  2.1799e-01,\n",
       "          3.4460e-02, -3.9290e-01, -2.0939e-01,  2.6912e-01,  5.8355e-02,\n",
       "          1.5592e-01,  4.5125e-01, -2.2618e-01, -1.5144e-01,  1.1064e-02,\n",
       "         -5.4445e-02, -1.6974e-01, -2.6882e-01, -3.1612e-01,  3.9932e-01,\n",
       "          2.1221e-01,  1.6857e-02,  4.5951e-02,  3.9494e-01,  6.3640e-02,\n",
       "          4.9920e-02,  1.0221e-01, -1.7929e-01, -1.7855e-01,  3.4819e-02,\n",
       "         -1.4980e-01,  2.3086e-01, -7.5418e+00, -2.5987e-01, -1.3575e-01,\n",
       "         -3.3099e-01, -3.2811e-01, -2.6178e-01,  3.5162e-01, -4.0248e-01,\n",
       "          3.3750e-01, -1.8999e-01,  7.4464e-02, -2.0133e-03, -1.6140e-01,\n",
       "         -4.1782e-02,  2.8878e-01,  3.2470e-01]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "DEFAULT_TOKENIZER = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "DEFAULT_MODEL = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "DEFAULT_MODEL.to('cpu')\n",
    "\n",
    "# 2. Tokenize input\n",
    "text = \"Replace me with any text you'd like.\"\n",
    "encoded_input = DEFAULT_TOKENIZER(text, return_tensors='pt', padding=True, truncation=True, max_length=15000)\n",
    "\n",
    "# 3. Get raw model outputs\n",
    "with torch.no_grad():\n",
    "    outputs = DEFAULT_MODEL(**encoded_input)\n",
    "outputs.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bb114",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_train, bert_val, bert_test = [], [], []\n",
    "for statement in train_df['statement']:\n",
    "  bert_train.append(helper.get_embeddings(statement))\n",
    "for statement in val_df['statement']:\n",
    "  bert_val.append(helper.get_embeddings(statement))\n",
    "for statement in test_df['statmeent']:\n",
    "  bert_test.append(helper.get_embeddings(statement))\n",
    "\n",
    "# For later use: np.vstack(df['bert_features'])\n",
    "train_df['bert_features'] = bert_train\n",
    "val_df['bert_features'] = bert_val\n",
    "test_df['bert_features'] = bert_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03984032",
   "metadata": {},
   "source": [
    "For the rest of the features, we'll do the same iterative process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For word ratios\n",
    "first_person_pronouns = ['i', 'me', 'my', 'mine', 'myself']\n",
    "negatives = ['no', 'not', 'never', 'nothing', 'wrong', 'nope']\n",
    "suicide_words = ['die', 'end', 'forever', 'leave', 'gone', 'suicide', 'kill']\n",
    "ratio_items = {'first_person_ratio' : first_person_pronouns, 'negatives_ratio': negatives, 'suicide_ratio': suicide_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cbbe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# List all functions\n",
    "feature2function = {\n",
    "  'word_ratio' : helper.word_ratio,\n",
    "  'reps_ratio' : helper.reps_ratio,\n",
    "  'character_count' : helper.character_count,\n",
    "  'word_count' : helper.word_count,\n",
    "  'avg_word_length' : helper.avg_word_length,\n",
    "  'avg_sentence_length_in_words' : helper.avg_sentence_length_in_words,\n",
    "  'avg_sentence_length_in_characters' : helper.avg_sentence_length_in_characters,\n",
    "  'sia_sentiment' : helper.sia_sentiment,\n",
    "}\n",
    "\n",
    "for column in feature2function.keys():\n",
    "\n",
    "  function = feature2function[column]\n",
    "\n",
    "  if column == 'word_ratio':\n",
    "    for ratio in ratio_items.keys():\n",
    "\n",
    "      ratio_item = ratio_items[ratio]\n",
    "      new_col_train, new_col_val, new_col_test = [], [], []\n",
    "\n",
    "      for statement in train_df['statement']:\n",
    "        new_col_train.append(function(statement, ratio_item))\n",
    "      for statement in val_df['statement']:\n",
    "        new_col_val.append(function(statement, ratio_item))\n",
    "      for statement in test_df['statmeent']:\n",
    "        new_col_test.append(function(statement, ratio_item))\n",
    "\n",
    "      train_df[ratio] = new_col_train\n",
    "      val_df[ratio] = new_col_val\n",
    "      test_df[ratio] = new_col_test\n",
    "\n",
    "  elif 'avg_sentence' in column:\n",
    "\n",
    "    new_col_train, new_col_val, new_col_test = [], [], []\n",
    "\n",
    "    for statement in train_df['statement']:\n",
    "      sentences = sent_tokenize(statement)\n",
    "      new_col_train.append(function(sentences))\n",
    "    for statement in val_df['statement']:\n",
    "      sentences = sent_tokenize(statement)\n",
    "      new_col_val.append(function(sentences))\n",
    "    for statement in test_df['statmeent']:\n",
    "      sentences = sent_tokenize(statement)\n",
    "      new_col_test.append(function(sentences))\n",
    "\n",
    "    train_df[column] = new_col_train\n",
    "    val_df[column] = new_col_val\n",
    "    test_df[column] = new_col_test\n",
    "\n",
    "  else:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3b5ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "train_df.to_csv('features_train.csv')\n",
    "val_df.to_csv('features_val.csv')\n",
    "test_df.to_csv('features_test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
